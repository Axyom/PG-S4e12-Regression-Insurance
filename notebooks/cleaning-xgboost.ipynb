{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615cf318",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.047888Z",
     "iopub.status.busy": "2024-12-09T13:12:34.047597Z",
     "iopub.status.idle": "2024-12-09T13:12:34.716436Z",
     "shell.execute_reply": "2024-12-09T13:12:34.715768Z"
    },
    "papermill": {
     "duration": 0.676501,
     "end_time": "2024-12-09T13:12:34.718408",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.041907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1522c74",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2024-12-09T13:12:34.727632",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.722781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25bf2667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.736529Z",
     "iopub.status.busy": "2024-12-09T13:12:34.736123Z",
     "iopub.status.idle": "2024-12-09T13:12:34.740000Z",
     "shell.execute_reply": "2024-12-09T13:12:34.739354Z"
    },
    "papermill": {
     "duration": 0.01006,
     "end_time": "2024-12-09T13:12:34.741432",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.731372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HYPER_OPT = True \n",
    "HYPER_OPT_TIME = 3600*5\n",
    "USE_ORIGINAL_DATA = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58ea0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.750060Z",
     "iopub.status.busy": "2024-12-09T13:12:34.749825Z",
     "iopub.status.idle": "2024-12-09T13:12:34.777850Z",
     "shell.execute_reply": "2024-12-09T13:12:34.776888Z"
    },
    "papermill": {
     "duration": 0.03404,
     "end_time": "2024-12-09T13:12:34.779346",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.745306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .db files have been copied to the output directory.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = Path(\"/kaggle/input\")\n",
    "output_dir = Path(\"/kaggle/working\")\n",
    "\n",
    "# Find and copy all .db files\n",
    "for db_file in input_dir.rglob(\"*.db\"):\n",
    "    shutil.copy(db_file, output_dir / db_file.name)\n",
    "\n",
    "print(\"All .db files have been copied to the output directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1038ad",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2024-12-09T13:12:34.787072",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.783372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6521eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Axyom\\\\Kaggle\\\\PG S4e12 - Regression Insurance\\\\notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743efa5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.795909Z",
     "iopub.status.busy": "2024-12-09T13:12:34.795667Z",
     "iopub.status.idle": "2024-12-09T13:12:43.929071Z",
     "shell.execute_reply": "2024-12-09T13:12:43.928139Z"
    },
    "papermill": {
     "duration": 9.140256,
     "end_time": "2024-12-09T13:12:43.931157",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.790901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory (where the notebook is running)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "\n",
    "# Construct file paths\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "original_file = os.path.join(data_dir, \"Insurance Premium Prediction Dataset.csv\")\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file, index_col=\"id\")\n",
    "test_df = pd.read_csv(test_file, index_col=\"id\")\n",
    "original_df = pd.read_csv(original_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f27ae",
   "metadata": {
    "papermill": {
     "duration": 0.003676,
     "end_time": "2024-12-09T13:12:43.939293",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.935617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621e65e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:43.948129Z",
     "iopub.status.busy": "2024-12-09T13:12:43.947854Z",
     "iopub.status.idle": "2024-12-09T13:12:43.984256Z",
     "shell.execute_reply": "2024-12-09T13:12:43.983521Z"
    },
    "papermill": {
     "duration": 0.043107,
     "end_time": "2024-12-09T13:12:43.986198",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.943091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_df = original_df.dropna(subset=[\"Premium Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d42d2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:43.995169Z",
     "iopub.status.busy": "2024-12-09T13:12:43.994928Z",
     "iopub.status.idle": "2024-12-09T13:12:50.925060Z",
     "shell.execute_reply": "2024-12-09T13:12:50.924366Z"
    },
    "papermill": {
     "duration": 6.936729,
     "end_time": "2024-12-09T13:12:50.926967",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.990238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df_in):\n",
    "    df = df_in.copy()\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    df[categorical_features] = df[categorical_features].fillna(\"Unknown\")\n",
    "\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    df[\"Policy Start Date\"] = pd.to_datetime(df[\"Policy Start Date\"])\n",
    "    df[\"Month\"]       = df[\"Policy Start Date\"].dt.month\n",
    "    df[\"Day\"]         = df[\"Policy Start Date\"].dt.day\n",
    "    df[\"Week\"]        = df[\"Policy Start Date\"].dt.isocalendar().week\n",
    "    df[\"Weekday\"]     = df[\"Policy Start Date\"].dt.weekday\n",
    "    df['DaySin']      = np.sin(2 * np.pi * df['Day'] / 30)  \n",
    "    df['DayCos']      = np.cos(2 * np.pi * df['Day'] / 30)\n",
    "    df['WeekdaySin']  = np.sin(2 * np.pi * df['Weekday'] / 7)\n",
    "    df['WeekdayCos']  = np.cos(2 * np.pi * df['Weekday'] / 7)\n",
    "    \n",
    "    df['DaysSinceStart']  = \\\n",
    "    np.ceil(\n",
    "        (pd.to_datetime(\"12-31-2024\") - df[\"Policy Start Date\"])/ pd.Timedelta(1, \"d\")\n",
    "    )\n",
    "\n",
    "    df = df.drop(\"Policy Start Date\", axis=1, errors = \"ignore\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "original_df = preprocess(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea2194",
   "metadata": {
    "papermill": {
     "duration": 0.00378,
     "end_time": "2024-12-09T13:12:50.934969",
     "exception": false,
     "start_time": "2024-12-09T13:12:50.931189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c14c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:50.943986Z",
     "iopub.status.busy": "2024-12-09T13:12:50.943322Z",
     "iopub.status.idle": "2024-12-09T13:12:51.006500Z",
     "shell.execute_reply": "2024-12-09T13:12:51.005817Z"
    },
    "papermill": {
     "duration": 0.069789,
     "end_time": "2024-12-09T13:12:51.008486",
     "exception": false,
     "start_time": "2024-12-09T13:12:50.938697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Premium Amount', axis=1)\n",
    "#X_train[\"Premium Amount\"] = np.log1p(X_train['Premium Amount'].values)\n",
    "y_train = pd.DataFrame(np.log1p(train_df['Premium Amount'].values))\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "if USE_ORIGINAL_DATA:\n",
    "    X_train[\"Synthetic\"] = 1\n",
    "    X_test[\"Synthetic\"] = 1\n",
    "    X_orig[\"Synthetic\"] = 0\n",
    "    X_orig = original_df.drop('Premium Amount', axis=1)\n",
    "    y_orig = pd.DataFrame(np.log1p(original_df['Premium Amount'].values))\n",
    "    \n",
    "else:\n",
    "    X_orig = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f3445",
   "metadata": {
    "papermill": {
     "duration": 0.00376,
     "end_time": "2024-12-09T13:12:51.016326",
     "exception": false,
     "start_time": "2024-12-09T13:12:51.012566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cfa320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:51.025389Z",
     "iopub.status.busy": "2024-12-09T13:12:51.025148Z",
     "iopub.status.idle": "2024-12-09T13:12:52.158782Z",
     "shell.execute_reply": "2024-12-09T13:12:52.157833Z"
    },
    "papermill": {
     "duration": 1.140683,
     "end_time": "2024-12-09T13:12:52.160796",
     "exception": false,
     "start_time": "2024-12-09T13:12:51.020113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def train_model_cv(model, X_train, y_train, X_test, X_orig, cv_splits=7, early_stopping_rounds=None):\n",
    "    # Initialize the K-Fold for CV\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=84)\n",
    "    \n",
    "    # Initialize placeholders for results\n",
    "    oof_preds = np.zeros(X_train.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "    cv_scores = np.zeros(cv_splits)\n",
    "    best_iterations = np.zeros(cv_splits)\n",
    "    models = []\n",
    "    \n",
    "    # Loop through each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        print(f\"Training fold {fold + 1}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        if X_orig is not None:\n",
    "            # Append rows\n",
    "            X_train_fold = pd.concat([X_train_fold, X_orig], ignore_index=True)\n",
    "            y_train_fold = pd.concat([y_train_fold, y_orig], ignore_index=True)\n",
    "        \n",
    "        # Fit the model on training data\n",
    "        if early_stopping_rounds:\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold, \n",
    "                eval_set=(X_val_fold, y_val_fold),\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose=False\n",
    "            )\n",
    "            best_iterations[fold]=model.get_best_iteration()\n",
    "        else:\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on validation and test data\n",
    "        oof_preds[val_idx] = model.predict(X_val_fold)\n",
    "        test_preds += model.predict(X_test)\n",
    "        \n",
    "        # Calculate score for this fold\n",
    "        fold_score = mean_squared_error(y_val_fold, oof_preds[val_idx], squared=False)\n",
    "        cv_scores[fold] = fold_score\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} RMSE: {fold_score:.4f}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    test_preds /= cv_splits\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    std_score = np.std(cv_scores)\n",
    "    best_iteration = best_iterations.mean()\n",
    "    print(f\"Mean CV RMSE: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "\n",
    "    return {\\\n",
    "        \"oof_preds\": oof_preds,\n",
    "        \"test_preds\": test_preds,\n",
    "        \"cv_scores\": cv_scores,\n",
    "        \"models\": models,\n",
    "        \"best_iteration\": int(best_iterations.mean())\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911be5c",
   "metadata": {
    "papermill": {
     "duration": 0.003666,
     "end_time": "2024-12-09T13:12:52.168747",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.165081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBOOST Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b4468ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:52.177511Z",
     "iopub.status.busy": "2024-12-09T13:12:52.177082Z",
     "iopub.status.idle": "2024-12-09T13:12:52.389730Z",
     "shell.execute_reply": "2024-12-09T13:12:52.389032Z"
    },
    "papermill": {
     "duration": 0.219154,
     "end_time": "2024-12-09T13:12:52.391567",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.172413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import pandas as pd\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "class XGBRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, early_stopping_rounds=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Train the XGBRegressor model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: pd.DataFrame or array-like\n",
    "          Training features.\n",
    "        - y: array-like\n",
    "          Training labels.\n",
    "        - eval_set: tuple or None\n",
    "          Optional validation set for early stopping, in the form [(X_val, y_val)].\n",
    "        - early_stopping_rounds: int or None\n",
    "          Number of rounds for early stopping. Set to None to disable.\n",
    "        - verbose: bool\n",
    "          Whether to print training progress.\n",
    "        \"\"\"\n",
    "        # Ensure X is a DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # Initialize and train the XGB Regressor\n",
    "        self.params[\"early_stopping_rounds\"] = early_stopping_rounds \n",
    "        \n",
    "        self.xgb_model_ = XGBRegressor(**self.params)\n",
    "        \n",
    "        # callbacks = []\n",
    "        # if early_stopping_rounds and eval_set:\n",
    "        #     callbacks.append(EarlyStopping(rounds=early_stopping_rounds, save_best=True, maximize=False, metric_name=\"rmse\"))\n",
    "\n",
    "\n",
    "        # Train the model with early stopping if validation set is provided\n",
    "        self.xgb_model_.fit(\n",
    "            X,\n",
    "            y,\n",
    "            eval_set=[eval_set],\n",
    "            #early_stopping_rounds=early_stopping_rounds,\n",
    "            #callbacks=callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.xgb_model_.predict(X)\n",
    "\n",
    "    def get_best_iteration(self):\n",
    "        \"\"\"\n",
    "        Get the best iteration for early stopping.\n",
    "        \"\"\"\n",
    "        return self.xgb_model_.best_iteration if hasattr(self.xgb_model_, \"best_iteration\") else None\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        self.params.update(parameters)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1a39",
   "metadata": {
    "papermill": {
     "duration": 0.003711,
     "end_time": "2024-12-09T13:12:52.399442",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.395731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63616760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:52.408413Z",
     "iopub.status.busy": "2024-12-09T13:12:52.407769Z",
     "iopub.status.idle": "2024-12-09T18:16:55.180521Z",
     "shell.execute_reply": "2024-12-09T18:16:55.179660Z"
    },
    "papermill": {
     "duration": 18242.779653,
     "end_time": "2024-12-09T18:16:55.182810",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.403157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-10 17:07:44,980] Using an existing study with name 'XGB_v1' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSE: 1.0511\n",
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 RMSE: 1.0502\n",
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 RMSE: 1.0486\n",
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 RMSE: 1.0511\n",
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-12-10 17:09:44,554] Trial 8 finished with value: 1.0501551784244039 and parameters: {'learning_rate': 0.05433350003437882, 'max_depth': 14, 'min_child_weight': 1.509804001525835, 'subsample': 0.8367148343488449, 'colsample_bytree': 0.9708747744678036, 'gamma': 0.06351598517383816, 'lambda': 0.04511809923805299, 'alpha': 0.0015676574662308934}. Best is trial 8 with value: 1.0501551784244039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 RMSE: 1.0498\n",
      "Mean CV RMSE: 1.0502 ± 0.0009\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-12-10 17:10:06,958] Trial 9 failed with parameters: {'learning_rate': 0.001768215377734423, 'max_depth': 12, 'min_child_weight': 0.008728853020978604, 'subsample': 0.8464925012884582, 'colsample_bytree': 0.5157352018243503, 'gamma': 3.5042237608299063, 'lambda': 0.014890607747597583, 'alpha': 1.2529040614881077} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Axyom\\AppData\\Local\\Temp\\ipykernel_12292\\1840419637.py\", line 43, in objective\n",
      "    results = train_model_cv(\\\n",
      "  File \"C:\\Users\\Axyom\\AppData\\Local\\Temp\\ipykernel_12292\\1576233961.py\", line 31, in train_model_cv\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\Axyom\\AppData\\Local\\Temp\\ipykernel_12292\\1610046470.py\", line 41, in fit\n",
      "    self.xgb_model_.fit(\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-10 17:10:06,959] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 71\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Replace X_train, y_train, and X_test with your data\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# X_train, X_test, y_train = ...\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Run Optuna optimization\u001b[39;00m\n\u001b[0;32m     64\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study( \\\n\u001b[0;32m     65\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     66\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGB_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m666\u001b[39m)\n\u001b[0;32m     70\u001b[0m )\n\u001b[1;32m---> 71\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHYPER_OPT_TIME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Best parameters and result\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Trial: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[24], line 43\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressorWrapper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgb_params)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Evaluate using K-Fold CV with early stopping\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_orig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m score \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     54\u001b[0m trial\u001b[38;5;241m.\u001b[39mset_user_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[9], line 31\u001b[0m, in \u001b[0;36mtrain_model_cv\u001b[1;34m(model, X_train, y_train, X_test, X_orig, cv_splits, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the model on training data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stopping_rounds:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     best_iterations[fold]\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_best_iteration()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[23], line 41\u001b[0m, in \u001b[0;36mXGBRegressorWrapper.fit\u001b[1;34m(self, X, y, eval_set, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxgb_model_ \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# callbacks = []\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# if early_stopping_rounds and eval_set:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#     callbacks.append(EarlyStopping(rounds=early_stopping_rounds, save_best=True, maximize=False, metric_name=\"rmse\"))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping if validation set is provided\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgb_model_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#early_stopping_rounds=early_stopping_rounds,\u001b[39;49;00m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=callbacks,\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import optuna\n",
    "import torch\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history, \n",
    "    plot_param_importances, \n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice,\n",
    "    plot_contour\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if HYPER_OPT:\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"reg:squarederror\",  # XGBoost regression objective\n",
    "        \"tree_method\": \"gpu_hist\" if torch.cuda.is_available() else \"auto\",\n",
    "        \"verbosity\": 0,\n",
    "        \"enable_categorical\": True\n",
    "    }\n",
    "    \n",
    "    # Define the Optuna objective function\n",
    "    def objective(trial):\n",
    "        # Define hyperparameter space\n",
    "        varying_params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 8, 15),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 50, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10, log=True)\n",
    "        }\n",
    "\n",
    "        xgb_params = {**fixed_params, **varying_params}\n",
    "        \n",
    "        # Initialize XGBRegressor with trial parameters\n",
    "        model = XGBRegressorWrapper(**xgb_params)\n",
    "        \n",
    "        # Evaluate using K-Fold CV with early stopping\n",
    "        results = train_model_cv(\\\n",
    "            model, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test, \n",
    "            X_orig,\n",
    "            cv_splits=5, \n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        score = results['cv_scores'].mean()\n",
    "\n",
    "        trial.set_user_attr(\"best_iteration\", results['best_iteration'])\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    # Prepare data\n",
    "    # Replace X_train, y_train, and X_test with your data\n",
    "    # Example:\n",
    "    # X_train, X_test, y_train = ...\n",
    "    \n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study( \\\n",
    "        direction=\"minimize\", \n",
    "        study_name=\"XGB_v1\", \n",
    "        storage=\"sqlite:///xgb_study_v1.db\", \n",
    "        load_if_exists=True,\n",
    "        sampler=TPESampler(seed=666)\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=HYPER_OPT_TIME)\n",
    "    \n",
    "    # Best parameters and result\n",
    "    print(\"Best Trial: \", study.best_trial.params)\n",
    "    print(\"Best RMSE: \", study.best_value)\n",
    "\n",
    "    xgb_best_params = {**fixed_params, **study.best_trial.params}\n",
    "\n",
    "    xgb_best_params[\"n_estimators\"] = study.best_trial.user_attrs.get(\"best_iteration\", None)\n",
    "\n",
    "    with open(\"xgb_best_params.json\", \"w\") as f:\n",
    "        json.dump(xgb_best_params, f, indent=4)\n",
    "   \n",
    "    plot_optimization_history(study)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_param_importances(study)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_slice(study)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    xgb_best_params = {\n",
    "        \"n_estimators\": 8401,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"tree_method\": \"auto\",\n",
    "        \"verbosity\": 0,\n",
    "        \"enable_categorical\": True,\n",
    "        \"learning_rate\": 0.001768215377734423,\n",
    "        \"max_depth\": 12,\n",
    "        \"min_child_weight\": 0.008728853020978604,\n",
    "        \"subsample\": 0.8464925012884582,\n",
    "        \"colsample_bytree\": 0.5157352018243503,\n",
    "        \"gamma\": 3.5042237608299063,\n",
    "        \"lambda\": 0.014890607747597583,\n",
    "        \"alpha\": 1.2529040614881077\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d5c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.241304Z",
     "iopub.status.busy": "2024-12-09T18:16:55.240196Z",
     "iopub.status.idle": "2024-12-09T18:16:55.246167Z",
     "shell.execute_reply": "2024-12-09T18:16:55.245357Z"
    },
    "papermill": {
     "duration": 0.035916,
     "end_time": "2024-12-09T18:16:55.247704",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.211788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 3388,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'verbosity': 0,\n",
       " 'enable_categorical': True,\n",
       " 'learning_rate': 0.0019183388163566096,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 11.13254860561508,\n",
       " 'subsample': 0.8083537031924297,\n",
       " 'colsample_bytree': 0.9656438477131202,\n",
       " 'gamma': 3.2972521618813926,\n",
       " 'lambda': 2.065890933462914,\n",
       " 'alpha': 0.10641557397683166}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e870ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.304289Z",
     "iopub.status.busy": "2024-12-09T18:16:55.303586Z",
     "iopub.status.idle": "2024-12-09T18:16:55.307059Z",
     "shell.execute_reply": "2024-12-09T18:16:55.306445Z"
    },
    "papermill": {
     "duration": 0.033579,
     "end_time": "2024-12-09T18:16:55.308644",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.275065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_best_params[\"n_estimators\"] = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bf058",
   "metadata": {
    "papermill": {
     "duration": 0.032715,
     "end_time": "2024-12-09T18:16:55.371337",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.338622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed4579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.437662Z",
     "iopub.status.busy": "2024-12-09T18:16:55.437325Z",
     "iopub.status.idle": "2024-12-09T18:27:05.981939Z",
     "shell.execute_reply": "2024-12-09T18:27:05.980966Z"
    },
    "papermill": {
     "duration": 610.608804,
     "end_time": "2024-12-09T18:27:06.012560",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.403756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSE: 1.0491\n",
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 RMSE: 1.0421\n",
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 RMSE: 1.0463\n",
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 RMSE: 1.0426\n",
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 RMSE: 1.0469\n",
      "Training fold 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 RMSE: 1.0479\n",
      "Training fold 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 RMSE: 1.0422\n",
      "Mean CV RMSE: 1.0453 ± 0.0027\n"
     ]
    }
   ],
   "source": [
    "# Initialize a CatBoost Regressor\n",
    "model = XGBRegressorWrapper(**xgb_best_params)\n",
    "\n",
    "# Use the train_model function to train and evaluate the model\n",
    "results = train_model_cv(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    X_orig=X_orig,\n",
    "    early_stopping_rounds=100,\n",
    "    cv_splits=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5d6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:06.069815Z",
     "iopub.status.busy": "2024-12-09T18:27:06.069512Z",
     "iopub.status.idle": "2024-12-09T18:27:06.074853Z",
     "shell.execute_reply": "2024-12-09T18:27:06.074183Z"
    },
    "papermill": {
     "duration": 0.035663,
     "end_time": "2024-12-09T18:27:06.076253",
     "exception": false,
     "start_time": "2024-12-09T18:27:06.040590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_score = np.mean(results[\"cv_scores\"])\n",
    "std_score = np.std(results[\"cv_scores\"])\n",
    "\n",
    "# Prepare the data\n",
    "data = {\n",
    "    \"mean_score\": mean_score,\n",
    "    \"std_score\": std_score\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"score.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)  # Use `indent` for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba76357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:06.134109Z",
     "iopub.status.busy": "2024-12-09T18:27:06.133614Z",
     "iopub.status.idle": "2024-12-09T18:27:09.560189Z",
     "shell.execute_reply": "2024-12-09T18:27:09.559255Z"
    },
    "papermill": {
     "duration": 3.457335,
     "end_time": "2024-12-09T18:27:09.561802",
     "exception": false,
     "start_time": "2024-12-09T18:27:06.104467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF predictions saved to oof_preds.csv.\n",
      "Test predictions saved to oof_preds.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_models.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save OOF predictions as a CSV file\n",
    "oof_preds_df = pd.DataFrame({\"oof_preds\": results[\"oof_preds\"]})\n",
    "oof_preds_df.to_csv(\"oof_preds.csv\", index=False)\n",
    "print(\"OOF predictions saved to oof_preds.csv.\")\n",
    "\n",
    "test_preds_df = pd.DataFrame({\"test_preds\": results[\"test_preds\"]})\n",
    "oof_preds_df.to_csv(\"test_preds.csv\", index=False)\n",
    "print(\"Test predictions saved to oof_preds.csv.\")\n",
    "\n",
    "joblib.dump(results[\"models\"], \"xgboost_models.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e1999",
   "metadata": {
    "papermill": {
     "duration": 0.030518,
     "end_time": "2024-12-09T18:27:09.621403",
     "exception": false,
     "start_time": "2024-12-09T18:27:09.590885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fab64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:09.684611Z",
     "iopub.status.busy": "2024-12-09T18:27:09.683845Z",
     "iopub.status.idle": "2024-12-09T18:27:11.039199Z",
     "shell.execute_reply": "2024-12-09T18:27:11.038523Z"
    },
    "papermill": {
     "duration": 1.388863,
     "end_time": "2024-12-09T18:27:11.041168",
     "exception": false,
     "start_time": "2024-12-09T18:27:09.652305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = np.expm1(results['test_preds'])\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test.index,  \n",
    "    'Premium Amount': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb004a",
   "metadata": {
    "papermill": {
     "duration": 0.028392,
     "end_time": "2024-12-09T18:27:11.099295",
     "exception": false,
     "start_time": "2024-12-09T18:27:11.070903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "sourceId": 84896,
     "sourceType": "competition"
    },
    {
     "datasetId": 5547076,
     "sourceId": 9178166,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211948002,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18880.993655,
   "end_time": "2024-12-09T18:27:12.649632",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-09T13:12:31.655977",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

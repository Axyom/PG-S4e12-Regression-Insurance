{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615cf318",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.047888Z",
     "iopub.status.busy": "2024-12-09T13:12:34.047597Z",
     "iopub.status.idle": "2024-12-09T13:12:34.716436Z",
     "shell.execute_reply": "2024-12-09T13:12:34.715768Z"
    },
    "papermill": {
     "duration": 0.676501,
     "end_time": "2024-12-09T13:12:34.718408",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.041907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1522c74",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2024-12-09T13:12:34.727632",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.722781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25bf2667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.736529Z",
     "iopub.status.busy": "2024-12-09T13:12:34.736123Z",
     "iopub.status.idle": "2024-12-09T13:12:34.740000Z",
     "shell.execute_reply": "2024-12-09T13:12:34.739354Z"
    },
    "papermill": {
     "duration": 0.01006,
     "end_time": "2024-12-09T13:12:34.741432",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.731372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HYPER_OPT = False \n",
    "HYPER_OPT_TIME = 3600*5\n",
    "USE_ORIGINAL_DATA = False \n",
    "SUBMIT_TO_KAGGLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1038ad",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2024-12-09T13:12:34.787072",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.783372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743efa5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:34.795909Z",
     "iopub.status.busy": "2024-12-09T13:12:34.795667Z",
     "iopub.status.idle": "2024-12-09T13:12:43.929071Z",
     "shell.execute_reply": "2024-12-09T13:12:43.928139Z"
    },
    "papermill": {
     "duration": 9.140256,
     "end_time": "2024-12-09T13:12:43.931157",
     "exception": false,
     "start_time": "2024-12-09T13:12:34.790901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory (where the notebook is running)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "\n",
    "model_dir = os.path.join(base_dir, \"models\")\n",
    "\n",
    "# Construct file paths\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "original_file = os.path.join(data_dir, \"Insurance Premium Prediction Dataset.csv\")\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file, index_col=\"id\")\n",
    "test_df = pd.read_csv(test_file, index_col=\"id\")\n",
    "original_df = pd.read_csv(original_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f27ae",
   "metadata": {
    "papermill": {
     "duration": 0.003676,
     "end_time": "2024-12-09T13:12:43.939293",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.935617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "621e65e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:43.948129Z",
     "iopub.status.busy": "2024-12-09T13:12:43.947854Z",
     "iopub.status.idle": "2024-12-09T13:12:43.984256Z",
     "shell.execute_reply": "2024-12-09T13:12:43.983521Z"
    },
    "papermill": {
     "duration": 0.043107,
     "end_time": "2024-12-09T13:12:43.986198",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.943091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_df = original_df.dropna(subset=[\"Premium Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d42d2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:43.995169Z",
     "iopub.status.busy": "2024-12-09T13:12:43.994928Z",
     "iopub.status.idle": "2024-12-09T13:12:50.925060Z",
     "shell.execute_reply": "2024-12-09T13:12:50.924366Z"
    },
    "papermill": {
     "duration": 6.936729,
     "end_time": "2024-12-09T13:12:50.926967",
     "exception": false,
     "start_time": "2024-12-09T13:12:43.990238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df_in):\n",
    "    df = df_in.copy()\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    df[categorical_features] = df[categorical_features].fillna(\"Unknown\")\n",
    "\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    df[\"Policy Start Date\"] = pd.to_datetime(df[\"Policy Start Date\"])\n",
    "    df[\"Month\"]       = df[\"Policy Start Date\"].dt.month\n",
    "    df[\"Day\"]         = df[\"Policy Start Date\"].dt.day\n",
    "    df[\"Week\"]        = df[\"Policy Start Date\"].dt.isocalendar().week\n",
    "    df[\"Weekday\"]     = df[\"Policy Start Date\"].dt.weekday\n",
    "    df['DaySin']      = np.sin(2 * np.pi * df['Day'] / 30)  \n",
    "    df['DayCos']      = np.cos(2 * np.pi * df['Day'] / 30)\n",
    "    df['WeekdaySin']  = np.sin(2 * np.pi * df['Weekday'] / 7)\n",
    "    df['WeekdayCos']  = np.cos(2 * np.pi * df['Weekday'] / 7)\n",
    "    \n",
    "    df['DaysSinceStart']  = \\\n",
    "    np.ceil(\n",
    "        (pd.to_datetime(\"12-31-2024\") - df[\"Policy Start Date\"])/ pd.Timedelta(1, \"d\")\n",
    "    )\n",
    "\n",
    "    df = df.drop(\"Policy Start Date\", axis=1, errors = \"ignore\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "original_df = preprocess(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea2194",
   "metadata": {
    "papermill": {
     "duration": 0.00378,
     "end_time": "2024-12-09T13:12:50.934969",
     "exception": false,
     "start_time": "2024-12-09T13:12:50.931189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c14c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:50.943986Z",
     "iopub.status.busy": "2024-12-09T13:12:50.943322Z",
     "iopub.status.idle": "2024-12-09T13:12:51.006500Z",
     "shell.execute_reply": "2024-12-09T13:12:51.005817Z"
    },
    "papermill": {
     "duration": 0.069789,
     "end_time": "2024-12-09T13:12:51.008486",
     "exception": false,
     "start_time": "2024-12-09T13:12:50.938697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Premium Amount', axis=1)\n",
    "#X_train[\"Premium Amount\"] = np.log1p(X_train['Premium Amount'].values)\n",
    "y_train = pd.DataFrame(np.log1p(train_df['Premium Amount'].values))\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "if USE_ORIGINAL_DATA:\n",
    "    X_train[\"Synthetic\"] = 1\n",
    "    X_test[\"Synthetic\"] = 1\n",
    "    X_orig = original_df.drop('Premium Amount', axis=1)\n",
    "    X_orig[\"Synthetic\"] = 0\n",
    "    y_orig = pd.DataFrame(np.log1p(original_df['Premium Amount'].values))\n",
    "    \n",
    "else:\n",
    "    X_orig = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f3445",
   "metadata": {
    "papermill": {
     "duration": 0.00376,
     "end_time": "2024-12-09T13:12:51.016326",
     "exception": false,
     "start_time": "2024-12-09T13:12:51.012566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cfa320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:51.025389Z",
     "iopub.status.busy": "2024-12-09T13:12:51.025148Z",
     "iopub.status.idle": "2024-12-09T13:12:52.158782Z",
     "shell.execute_reply": "2024-12-09T13:12:52.157833Z"
    },
    "papermill": {
     "duration": 1.140683,
     "end_time": "2024-12-09T13:12:52.160796",
     "exception": false,
     "start_time": "2024-12-09T13:12:51.020113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def train_model_cv(model, X_train, y_train, X_test, X_orig, cv_splits=7, early_stopping_rounds=None):\n",
    "    # Initialize the K-Fold for CV\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=84)\n",
    "    \n",
    "    # Initialize placeholders for results\n",
    "    oof_preds = np.zeros(X_train.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "    cv_scores = np.zeros(cv_splits)\n",
    "    best_iterations = np.zeros(cv_splits)\n",
    "    models = []\n",
    "    \n",
    "    # Loop through each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        print(f\"Training fold {fold + 1}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        if X_orig is not None:\n",
    "            # Append rows\n",
    "            X_train_fold = pd.concat([X_train_fold, X_orig], ignore_index=True)\n",
    "            y_train_fold = pd.concat([y_train_fold, y_orig], ignore_index=True)\n",
    "        \n",
    "        # Fit the model on training data\n",
    "        if early_stopping_rounds:\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold, \n",
    "                eval_set=(X_val_fold, y_val_fold),\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose=False\n",
    "            )\n",
    "            best_iterations[fold]=model.get_best_iteration()\n",
    "        else:\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on validation and test data\n",
    "        oof_preds[val_idx] = model.predict(X_val_fold)\n",
    "        test_preds += model.predict(X_test)\n",
    "        \n",
    "        # Calculate score for this fold\n",
    "        fold_score = root_mean_squared_error(y_val_fold, oof_preds[val_idx])\n",
    "        cv_scores[fold] = fold_score\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} RMSE: {fold_score:.4f}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    test_preds /= cv_splits\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    std_score = np.std(cv_scores)\n",
    "    best_iteration = best_iterations.mean()\n",
    "    print(f\"Mean CV RMSE: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "\n",
    "    return {\\\n",
    "        \"oof_preds\": oof_preds,\n",
    "        \"test_preds\": test_preds,\n",
    "        \"cv_scores\": cv_scores,\n",
    "        \"models\": models,\n",
    "        \"best_iteration\": int(best_iterations.mean())\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911be5c",
   "metadata": {
    "papermill": {
     "duration": 0.003666,
     "end_time": "2024-12-09T13:12:52.168747",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.165081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBOOST Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4468ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:52.177511Z",
     "iopub.status.busy": "2024-12-09T13:12:52.177082Z",
     "iopub.status.idle": "2024-12-09T13:12:52.389730Z",
     "shell.execute_reply": "2024-12-09T13:12:52.389032Z"
    },
    "papermill": {
     "duration": 0.219154,
     "end_time": "2024-12-09T13:12:52.391567",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.172413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import pandas as pd\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "class XGBRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, early_stopping_rounds=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Train the XGBRegressor model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: pd.DataFrame or array-like\n",
    "          Training features.\n",
    "        - y: array-like\n",
    "          Training labels.\n",
    "        - eval_set: tuple or None\n",
    "          Optional validation set for early stopping, in the form [(X_val, y_val)].\n",
    "        - early_stopping_rounds: int or None\n",
    "          Number of rounds for early stopping. Set to None to disable.\n",
    "        - verbose: bool\n",
    "          Whether to print training progress.\n",
    "        \"\"\"\n",
    "        # Ensure X is a DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # Initialize and train the XGB Regressor\n",
    "        self.params[\"early_stopping_rounds\"] = early_stopping_rounds \n",
    "        \n",
    "        self.xgb_model_ = XGBRegressor(**self.params)\n",
    "        \n",
    "        # callbacks = []\n",
    "        # if early_stopping_rounds and eval_set:\n",
    "        #     callbacks.append(EarlyStopping(rounds=early_stopping_rounds, save_best=True, maximize=False, metric_name=\"rmse\"))\n",
    "\n",
    "\n",
    "        # Train the model with early stopping if validation set is provided\n",
    "        self.xgb_model_.fit(\n",
    "            X,\n",
    "            y,\n",
    "            eval_set=[eval_set],\n",
    "            #early_stopping_rounds=early_stopping_rounds,\n",
    "            #callbacks=callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.xgb_model_.predict(X)\n",
    "\n",
    "    def get_best_iteration(self):\n",
    "        \"\"\"\n",
    "        Get the best iteration for early stopping.\n",
    "        \"\"\"\n",
    "        return self.xgb_model_.best_iteration if hasattr(self.xgb_model_, \"best_iteration\") else None\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        self.params.update(parameters)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1a39",
   "metadata": {
    "papermill": {
     "duration": 0.003711,
     "end_time": "2024-12-09T13:12:52.399442",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.395731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63616760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:12:52.408413Z",
     "iopub.status.busy": "2024-12-09T13:12:52.407769Z",
     "iopub.status.idle": "2024-12-09T18:16:55.180521Z",
     "shell.execute_reply": "2024-12-09T18:16:55.179660Z"
    },
    "papermill": {
     "duration": 18242.779653,
     "end_time": "2024-12-09T18:16:55.182810",
     "exception": false,
     "start_time": "2024-12-09T13:12:52.403157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import optuna\n",
    "import torch\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history, \n",
    "    plot_param_importances, \n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice,\n",
    "    plot_contour\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if HYPER_OPT:\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"reg:squarederror\",  # XGBoost regression objective\n",
    "        \"tree_method\": \"gpu_hist\" if torch.cuda.is_available() else \"auto\",\n",
    "        \"verbosity\": 0,\n",
    "        \"enable_categorical\": True\n",
    "    }\n",
    "    \n",
    "    # Define the Optuna objective function\n",
    "    def objective(trial):\n",
    "        # Define hyperparameter space\n",
    "        varying_params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 8, 15),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 50, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10, log=True)\n",
    "        }\n",
    "\n",
    "        xgb_params = {**fixed_params, **varying_params}\n",
    "        \n",
    "        # Initialize XGBRegressor with trial parameters\n",
    "        model = XGBRegressorWrapper(**xgb_params)\n",
    "        \n",
    "        # Evaluate using K-Fold CV with early stopping\n",
    "        results = train_model_cv(\\\n",
    "            model, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_test, \n",
    "            X_orig,\n",
    "            cv_splits=5, \n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        score = results['cv_scores'].mean()\n",
    "\n",
    "        trial.set_user_attr(\"best_iteration\", results['best_iteration'])\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    # Prepare data\n",
    "    # Replace X_train, y_train, and X_test with your data\n",
    "    # Example:\n",
    "    # X_train, X_test, y_train = ...\n",
    "    \n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study( \\\n",
    "        direction=\"minimize\", \n",
    "        study_name=\"XGB_v1\", \n",
    "        storage=\"sqlite:///xgb_study_v1.db\", \n",
    "        load_if_exists=True,\n",
    "        sampler=TPESampler(seed=666)\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=HYPER_OPT_TIME)\n",
    "    \n",
    "    # Best parameters and result\n",
    "    print(\"Best Trial: \", study.best_trial.params)\n",
    "    print(\"Best RMSE: \", study.best_value)\n",
    "\n",
    "    xgb_best_params = {**fixed_params, **study.best_trial.params}\n",
    "\n",
    "    xgb_best_params[\"n_estimators\"] = study.best_trial.user_attrs.get(\"best_iteration\", None)\n",
    "\n",
    "    with open(\"xgb_best_params.json\", \"w\") as f:\n",
    "        json.dump(xgb_best_params, f, indent=4)\n",
    "   \n",
    "    plot_optimization_history(study)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_param_importances(study)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_slice(study)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    xgb_best_params = {\n",
    "        'n_estimators': 2225,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'verbosity': 0,\n",
    "        'enable_categorical': True,\n",
    "        'learning_rate': 0.003059929305190928,\n",
    "        'max_depth': 8,\n",
    "        'min_child_weight': 12.496270561250991,\n",
    "        'subsample': 0.8428246186530037,\n",
    "        'colsample_bytree': 0.9999895920675128,\n",
    "        'gamma': 2.937438656382514,\n",
    "        'lambda': 1.5752155403171972,\n",
    "        'alpha': 0.4038060866963702\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743d5c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.241304Z",
     "iopub.status.busy": "2024-12-09T18:16:55.240196Z",
     "iopub.status.idle": "2024-12-09T18:16:55.246167Z",
     "shell.execute_reply": "2024-12-09T18:16:55.245357Z"
    },
    "papermill": {
     "duration": 0.035916,
     "end_time": "2024-12-09T18:16:55.247704",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.211788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2225,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'verbosity': 0,\n",
       " 'enable_categorical': True,\n",
       " 'learning_rate': 0.003059929305190928,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 12.496270561250991,\n",
       " 'subsample': 0.8428246186530037,\n",
       " 'colsample_bytree': 0.9999895920675128,\n",
       " 'gamma': 2.937438656382514,\n",
       " 'lambda': 1.5752155403171972,\n",
       " 'alpha': 0.4038060866963702}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e870ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.304289Z",
     "iopub.status.busy": "2024-12-09T18:16:55.303586Z",
     "iopub.status.idle": "2024-12-09T18:16:55.307059Z",
     "shell.execute_reply": "2024-12-09T18:16:55.306445Z"
    },
    "papermill": {
     "duration": 0.033579,
     "end_time": "2024-12-09T18:16:55.308644",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.275065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_best_params[\"n_estimators\"] = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bf058",
   "metadata": {
    "papermill": {
     "duration": 0.032715,
     "end_time": "2024-12-09T18:16:55.371337",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.338622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ed4579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:16:55.437662Z",
     "iopub.status.busy": "2024-12-09T18:16:55.437325Z",
     "iopub.status.idle": "2024-12-09T18:27:05.981939Z",
     "shell.execute_reply": "2024-12-09T18:27:05.980966Z"
    },
    "papermill": {
     "duration": 610.608804,
     "end_time": "2024-12-09T18:27:06.012560",
     "exception": false,
     "start_time": "2024-12-09T18:16:55.403756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 RMSE: 1.0491\n",
      "Training fold 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressorWrapper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgb_best_params)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Use the train_model function to train and evaluate the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_orig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_orig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m, in \u001b[0;36mtrain_model_cv\u001b[1;34m(model, X_train, y_train, X_test, X_orig, cv_splits, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the model on training data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stopping_rounds:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     best_iterations[fold]\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_best_iteration()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m, in \u001b[0;36mXGBRegressorWrapper.fit\u001b[1;34m(self, X, y, eval_set, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxgb_model_ \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# callbacks = []\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# if early_stopping_rounds and eval_set:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#     callbacks.append(EarlyStopping(rounds=early_stopping_rounds, save_best=True, maximize=False, metric_name=\"rmse\"))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping if validation set is provided\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgb_model_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#early_stopping_rounds=early_stopping_rounds,\u001b[39;49;00m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=callbacks,\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Axyom\\anaconda3\\envs\\kaggle_env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize a CatBoost Regressor\n",
    "model = XGBRegressorWrapper(**xgb_best_params)\n",
    "\n",
    "# Use the train_model function to train and evaluate the model\n",
    "results = train_model_cv(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    X_orig=X_orig,\n",
    "    early_stopping_rounds=100,\n",
    "    cv_splits=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5d6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:06.069815Z",
     "iopub.status.busy": "2024-12-09T18:27:06.069512Z",
     "iopub.status.idle": "2024-12-09T18:27:06.074853Z",
     "shell.execute_reply": "2024-12-09T18:27:06.074183Z"
    },
    "papermill": {
     "duration": 0.035663,
     "end_time": "2024-12-09T18:27:06.076253",
     "exception": false,
     "start_time": "2024-12-09T18:27:06.040590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_score = np.mean(results[\"cv_scores\"])\n",
    "std_score = np.std(results[\"cv_scores\"])\n",
    "\n",
    "# Prepare the data\n",
    "data = {\n",
    "    \"mean_score\": mean_score,\n",
    "    \"std_score\": std_score\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"score.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)  # Use `indent` for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba76357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:06.134109Z",
     "iopub.status.busy": "2024-12-09T18:27:06.133614Z",
     "iopub.status.idle": "2024-12-09T18:27:09.560189Z",
     "shell.execute_reply": "2024-12-09T18:27:09.559255Z"
    },
    "papermill": {
     "duration": 3.457335,
     "end_time": "2024-12-09T18:27:09.561802",
     "exception": false,
     "start_time": "2024-12-09T18:27:06.104467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF predictions saved to oof_preds.csv.\n",
      "Test predictions saved to oof_preds.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_models.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save OOF predictions as a CSV file\n",
    "oof_preds_df = pd.DataFrame({\"oof_preds\": results[\"oof_preds\"]})\n",
    "oof_preds_df.to_csv(\"oof_preds\", index=False)\n",
    "print(\"OOF predictions saved to oof_preds.csv.\")\n",
    "\n",
    "test_preds_df = pd.DataFrame({\"test_preds\": results[\"test_preds\"]})\n",
    "test_preds_df.to_csv(\"test_preds\", index=False)\n",
    "print(\"Test predictions saved to test_preds.csv.\")\n",
    "\n",
    "joblib.dump(results[\"models\"], \"xgboost_models.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e1999",
   "metadata": {
    "papermill": {
     "duration": 0.030518,
     "end_time": "2024-12-09T18:27:09.621403",
     "exception": false,
     "start_time": "2024-12-09T18:27:09.590885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fab64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:27:09.684611Z",
     "iopub.status.busy": "2024-12-09T18:27:09.683845Z",
     "iopub.status.idle": "2024-12-09T18:27:11.039199Z",
     "shell.execute_reply": "2024-12-09T18:27:11.038523Z"
    },
    "papermill": {
     "duration": 1.388863,
     "end_time": "2024-12-09T18:27:11.041168",
     "exception": false,
     "start_time": "2024-12-09T18:27:09.652305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = np.expm1(results['test_preds'])\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test.index,  \n",
    "    'Premium Amount': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fdb004a",
   "metadata": {
    "papermill": {
     "duration": 0.028392,
     "end_time": "2024-12-09T18:27:11.099295",
     "exception": false,
     "start_time": "2024-12-09T18:27:11.070903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define your message and file paths\n",
    "COMP_NAME = \"playground-series-s4e12\"\n",
    "FILE_PATH = \"submission.csv\"\n",
    "mean_score = 155.0\n",
    "std_score = 2.0\n",
    "test_var=0\n",
    "\n",
    "SUBMIT_MESSAGE = f\"Clean XGB: Mean score: {mean_score:.4f} +/- {std_score:.4f}\"\n",
    "\n",
    "# Submit to Kaggle\n",
    "if SUBMIT_TO_KAGGLE: \n",
    "    os.system(f'kaggle competitions submit -c {COMP_NAME} -f {FILE_PATH} -m \"{SUBMIT_MESSAGE}\"')\n",
    "\n",
    "# Git commit and push\n",
    "GIT_COMMIT_MESSAGE = f\"Submission: {SUBMIT_MESSAGE}\"\n",
    "\n",
    "# Commands for Git\n",
    "os.system(\"code --command workbench.action.files.save\")\n",
    "os.system(\"git add .\")  # Stage all changes (adjust if you only want specific files)\n",
    "os.system(f'git commit -m \"{GIT_COMMIT_MESSAGE}\"')  # Commit changes with a message\n",
    "os.system(\"git push origin main\")  # Push to the main branch (change branch if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ef9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "sourceId": 84896,
     "sourceType": "competition"
    },
    {
     "datasetId": 5547076,
     "sourceId": 9178166,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211948002,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18880.993655,
   "end_time": "2024-12-09T18:27:12.649632",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-09T13:12:31.655977",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
